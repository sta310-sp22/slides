---
title: "Multilevel models"
subtitle: "Estimation + Interpretation"
date: "`r emo::ji('pie')` day 2022"
output:
  xaringan::moon_reader:
    #mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "sta310-slides.css"
    logo: sta310-sticker.png
    lib_dir: libs/font-awesome
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%" 
      ratio: "16:9"
    self_contained: true
---

```{r setup, include = F}
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE, 
                      fig.width = 8,
                      fig.asp = 0.618, 
                      fig.retina = 3, 
                      dpt = 300, 
                      out.width = "70%",
                      fig.align = "center")

ggplot2::theme_set(ggplot2::theme_bw(base_size = 16))

colors <- tibble::tibble(green = "#B5BA72")
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(GGally)
library(xaringanExtra)
library(knitr)
library(patchwork)
library(viridis)
library(ggfortify)
library(kableExtra)
library(lme4)
library(broom.mixed)
```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
```

class: middle, center

## [Click here for PDF of slides](17-multilevel-models-pt3.pdf)

---


## Announcements

- Quiz 03: Wed, Mar 16 - Fri, Mar 18 
  - Feb 21 - Mar 14 lectures

- DataFest: April 1 - 3 in Penn Pavilion 
  - [Click here](https://www2.stat.duke.edu/datafest/signup.html) to sign up 

---

## Mini-project 02 

[Click here](https://sta310-sp22.github.io/assignments/projects/mini-project-02.html) for project instructions

.vocab2[Updated timeline]

- **Draft for peer review**: due Thu, Mar 24 at 12pm (noon)
- **Peer reviews**: due Thu, Mar 24 at 11:59pm
- **Presentation**: due Mon, Mar 28 at 3:30pm
- **Written report**: due Mon, Mar 28 at 11:59pm

---

## Final project 

[Click here](https://sta310-sp22.github.io/assignments/projects/final-project.html) for project instructions


.vocab2[Timeline]

- **Round 1 submission (optional)**: Wednesday, April 13 at 11:59pm
- **Final submission**: Wednesday, April 27 at 11:59pm

---

## Mid-semester feedback

Thank you to everyone who filled out the mid-semester survey! 

.pull-left[

**What has helped with learning** 

- Working through interpretations and code in class
- HW and projects to extend learning beyond lectures


**How can teaching team help with learning** 

- More practice!
- Use some lab time for review and additional practice
]

.pull-right[
**Strategies you're using that have helped with learning**

- Engaging with the textbook
- Attending office hours
- Asking questions! 
]
  
---

## Learning goals 

- Fit and interpret multilevel models 

- Compare maximum likelihood (ML) and restricted maximum likelihood (REML) estimation approaches

- Understand general process for fitting and comparing multilevel models

---

## Data: Music performance anxiety 

.midi[The data [`musicdata.csv`](data/musicdata.csv) come from the Sadler and Miller (2010) study of the emotional state of musicians before performances. The dataset contains information collected from 37 undergraduate music majors who completed the Positive Affect Negative Affect Schedule (PANAS), an instrument produces a measure of anxiety (negative affect) and a measure of happiness (positive affect). This analysis will focus on negative affect as a measure of performance anxiety.]

The primary variables we'll use are

- **`na`**: negative affect score on PANAS (the response variable)
- **`LargeEnsemble`**: 1: performance is large ensemble; 0: performance is solo or small ensemble
- **`Orchestra`**: 1: orchestral instrument; 0: voice or piano
- **`mpqnem`**: negative emotionality (NEM) composite scale from MPQ

---

## Look at data

.small[
```{r echo = F}
music <- read_csv("data/musicdata.csv") %>%
  mutate(orchestra = factor(if_else(instrument == "orchestral instrument", 1, 0)), 
         large_ensemble = factor(if_else(perform_type == "Large Ensemble", 1, 0)))
music %>%
  filter(id %in% c(1, 43)) %>%
  group_by(id) %>%
  slice(1:3) %>%
  select(id, diary, large_ensemble, mpqnem, orchestra) %>%
  kable()
```
]

- `diary`, `na`, `large_ensemble` are **Level One** variables (performance-level variables)
- `orchestra`, `mpqnem` are **Level Two** variables (musician-level variables)




---

class: middle, inverse

## The model

### Model using `Orchestra` and `LargeEnsemble` to understand variability in performance anxiety (`na`)

---

## Two-stage model 

**Level One Model** 

$$na_{ij} = a_i + b_i ~ LargeEnsemble_{ij} + \epsilon_{ij}, \hspace{5mm} \epsilon_{ij} \sim N(0,\sigma^2)$$

**Level Two Models**

$$\begin{aligned}&a_i = \alpha_0 + \alpha_1 ~ Orchestra_i + u_i \\
&b_i = \beta_0 + \beta_1 ~ Orchestra_i + v_i\end{aligned}$$

---

## Composite model 

Plug in the equations for $a_i$ and $b_i$ to get the **composite model** 

.eq[
$$\begin{aligned}Y_{ij} &= (\alpha_0 + \alpha_1 ~ Orchestra_i + \beta_0 ~ LargeEnsemble_{ij} \\ 
&+ \beta_1 ~ Orchestra_i:LargeEnsemble_{ij})\\
&+ (u_i + v_i ~ LargeEnsemble_{ij} + \epsilon_{ij})\end{aligned}$$
]

--

- The **fixed effects** to estimate are $\alpha_0, \alpha_1, \beta_0, \beta_1$
- The **error terms** are $u_i, v_i, \epsilon_{ij}$
  - These describe the behavior of the random effects
--

When we use the composite model, we no longer need to estimate $a_i$ and $b_i$ directly as we did with the two-stage approach.

---

## Notation 

- Greek letters denote the fixed effect model parameters that will be estimated
  - e.g., $\alpha_0, \alpha_1, \beta_0, \beta_1$
  
- English letters denote the preliminary effects at lower levels that will not be estimated directly
  - e.g. $a_i, b_i$

- $\sigma$ and $\rho$ denote variance components that will be estimated 

- $\epsilon_{ij}, u_i, v_i$ denote error terms 

---

## Error terms

- Assume random effects are normally distributed with mean 0 and variance that will be estimated 

- **Level One**: Errors associated with each performance of a given musician are are normally distributed, i.e., $\epsilon_{ij} \sim N(0, \sigma^2)$

--

- **Level Two**: Errors are 
  - $u_i$: deviation of musician $i$ from the mean performance anxiety before solos and small ensembles after accounting for the instrument (musician-to-musician differences in intercept)
  - $v_i$: deviance of musician $i$ from the mean difference in performance anxiety between large ensembles and other performance types after accounting for instrument (musician-to-musician differences in slope)

--

- Need to account for correlation between $u_i$ and $v_i$ for the $i^{th}$ musician 

---

class: middle

```{r echo = F, fig.cap = "Recreated from Figure 8.11"}
model_stats <- tibble(slopes = rep(NA,37), 
               intercepts = rep(NA,37), 
               r.squared = rep(NA, 37))


ids <- music %>% distinct(id) %>% pull()

# counter to keep track of row number to store model_stats

count <- 1

for(i in ids){
  
individual_data <- music %>%
  filter(id == i)

n_perform_type <- individual_data %>% count(large_ensemble) %>% nrow()

if(n_perform_type > 1) {
  level_one_model <- lm(na ~ large_ensemble, data = individual_data)

level_one_model_tidy <- tidy(level_one_model)

model_stats$slopes[count] <- level_one_model_tidy$estimate[2]
model_stats$intercepts[count] <- level_one_model_tidy$estimate[1]
model_stats$r.squared[count] <- glance(level_one_model)$r.squared
}else{
  
model_stats$intercepts[count] <- mean(individual_data$na)
}

count = count + 1
}

musicians <- music %>%
  distinct(id, orchestra) %>%
  bind_cols(model_stats)

musicians %>%
  filter(!is.na(slopes)) %>%
ggplot(aes(x = intercepts, y = slopes)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  labs(x = "Fitted intercepts",
       y = "Fitted slopes", 
       title = "Fitted slopes and intercepts", 
       subtitle = paste0("r = ", round(cor(musicians %>% filter(!is.na(slopes)) %>% pull(intercepts), musicians %>% filter(!is.na(slopes)) %>% pull(slopes)),3)))
```

.center[**Describe the association between the slopes and intercepts.**]

---

## Distribution of Level Two errors

The Level Two error terms follow a **multivariate normal** distribution 

.eq[
$$\left[ \begin{array}{c}
            u_{i} \\ v_{i}
          \end{array}  \right] \sim N \left( \left[
          \begin{array}{c}
            0 \\ 0
          \end{array} \right], \left[
          \begin{array}{cc}
            \sigma_{u}^{2} & \rho_{uv}\sigma_{u}\sigma_v \\
            \rho_{uv}\sigma_{u}\sigma_v & \sigma_{v}^{2}
          \end{array} \right] \right)$$
          
where $\sigma^2_u$ and $\sigma^2_v$ are the variances of $u_i$'s and $v_i$'s respectively, $\rho_{uv}$ is the correlation between $u_i$ and $v_i$ 
]

Covariance:  $\sigma_{uv} =  \rho_{uv}\sigma_{u}\sigma_v$

- Indicates how those terms vary together
---

## Visualizing multivariate normal distribution 

```{r, include=FALSE}
library(mnormt)
#Code for next plot
e0 <- seq(-8,8,length=51)  
e1 <- seq(-4,4,length=51)
xy <- expand.grid(e0,e1)

Sigma <- matrix(c(4,0,0,1),2,2)
Mu <- c(0,0)
z <- dmnorm(xy, Mu, Sigma)
zframe <- data.frame(xy, z)
density <- xy[z==max(z),]
con.1 <- ggplot(data = zframe, aes(x = Var1, y = Var2, z = z)) + 
geom_contour(stat = "contour", lineend = "butt", 
               linejoin = "round", linemitre = 1, 
               na.rm = FALSE, colour = "black") + 
  labs(x = "u", y = "v", title = "MVN density", 
       subtitle = "no correlation ") + 
  scale_y_continuous(limits = c(-5,5))

# Positive correlation
Sigma <- matrix(c(4,1.5,1.5,1),2,2)
Mu <- c(0,0)
z <- dmnorm(xy, Mu, Sigma)
zframe <- data.frame(xy, z)
density <- xy[z==max(z),]
con.2 <- ggplot(data = zframe, aes(x = Var1, y = Var2, z = z)) + 
  geom_contour(stat = "contour", lineend = "butt", 
               linejoin = "round", linemitre = 1, 
               na.rm = FALSE, colour = "black") + 
  labs(x = "u", y = "v", title = "MVN dnesity", 
       subtitle = "positive correlation") + 
  scale_y_continuous(limits = c(-5,5))
```

```{r contour-boundary,fig.align="center",out.width="60%", fig.cap='Recreated from Figure 8.12',echo=FALSE, warning=FALSE}
con.1 + con.2
```

---

## Fit the model in R

Fit multilevel model using the `lmer` ("linear mixed effects in R") function from the **lme4** package.

```{r eval = F}
library(lme4)
music_model <- lmer(na ~ orchestra + large_ensemble + 
                      orchestra:large_ensemble + (large_ensemble|id), 
                    data = music)
```


--

`na ~ orchestra + large_ensemble + orchestra:large_ensemble`: Represents the fixed effects + intercept 

--

`(large_ensemble|id)`: Represents the error terms and associated variance components
  - Specifies two error terms: $u_i$ corresponding to the intercepts, $v_i$ corresponding to effect of large ensemble
  
---

## Tidy output 

Display results using the `tidy` function from the **broom.mixed** package. 

```{r eval = F}
library(broom.mixed)
tidy(music_model) 
```

- Get fixed effects only 

`tidy(music_model) %>% filter(effect == "fixed")`

- Get errors and variance components only

`tidy(music_model) %>% filter(effect == "ran_pars")`

---

## Model output: Fixed effects

```{r echo = F}
music_model <- lmer(na ~ orchestra + large_ensemble + 
                      orchestra:large_ensemble + (large_ensemble|id), data = music)

tidy(music_model) %>% filter(effect == "fixed") %>% kable(digits = 3)
```


.center[**Label the fixed effects**]

---

## Model output: Random effects

```{r echo = F}
tidy(music_model) %>% filter(effect == "ran_pars") %>% kable(digits = 3)
```


.center[**Label the error terms and variance components**]

---

## Interpret the effects 

- Split into 4 groups. 

- Each group will write the interpretation for one main effect and one variance component. The terms on each slide do not necessarily have a direct correspondence to each other. 

- One person write the group's interpretations on the slide. 

- [Click here](https://docs.google.com/presentation/d/17XvVYSG2NvhS-PJ8dwjdN8OodvmuCLE52r9-aGIJETw/edit?usp=sharing) for the slides.


```{r echo = F}
library(countdown)
countdown(minutes = 6, seconds = 00,
          margin = "1.25%")
```

---

class: middle, inverse

## Fitting the model 

---

## Comparing fixed effects estimates

Below are the estimated coefficients and standard errors for four modeling approaches.

```{r, include=FALSE}
Variable <- c("Intercept","Orch","Large","Orch*Large")
Independence <-c("15.72(0.36)", "1.79(0.55)", "-0.28(0.79)", "-1.71(1.06)")
`Two Stage` <- c("16.28(0.67)", "1.41(0.99)", "-0.77(0.85)", "-1.41(1.20)")
LVCF <- c("15.20(1.25)", "1.45(1.84)", "-", "-")
Multilevel <- c("15.93(0.64)", "1.69(0.95)", "-0.91(0.85)", "-1.42(1.10)")
```

```{r table3chp8,echo=FALSE}
table3chp8 <- data.frame(Variable, `Independence`, `Two Stage`, 
                         LVCF, Multilevel)
kable(table3chp8, booktabs=T, 
      caption="from BMLR Table 8.3")
```


.question[
- How do the coefficient estimates compare? 
- How do the standard errors compare? 
]

---

## ML and REML 

Maximum Likelihood (ML) and Restricted (Residual) Maximum Likelihood (REML) are the two most common methods for estimating the fixed effects and variance components

--

**Maximum Likelihood (ML)** 

- Jointly estimate the fixed effects and variance components using all the <u>sample data</u>
- Can be used to draw conclusions about fixed and random effects
- *Issue*: Fixed effects are treated as known values when estimating variance components
  - Results in biased estimates of variance components (especially when sample size is small)

---

## ML and REML 

**Restricted Maximum Likelihood (REML)**

- Estimate the variance components using the <u>sample residuals</u> not the sample data
- It is conditional on the fixed effects, so it accounts for uncertainty in fixed effects estimates. This results in unbiased estimates of variance components.

.center[
.question[
Example using OLS
]
]

.footnote[.small[See the post [Maximum Likelihood (ML) vs. REML](https://towardsdatascience.com/maximum-likelihood-ml-vs-reml-78cf79bef2cf) for details and illustration of ML vs. REML.]]

---

## ML or REML? 

- Research has not determined one method absolutely superior to the other

- **REML** (`REML = TRUE`; default in `lmer`) is preferable when 
  - the number of parameters is large or primary, or 
  - primary objective is to obtain estimates of the model parameters 

- **ML** (`REML = FALSE`) <u>must</u> be used if you want to compare nested fixed effects models using a likelihood ratio test (e.g., a drop-in-deviance test).
  - For REML, the goodness-of-fit and likelihood ratio tests can only be used to draw conclusions about variance components 

<br> 

.footnote[.small[Source: Singer, J. D. & Willett, J. B. (2003). *Applied longitudinal data analysis: Modeling change and event occurrence*. Oxford university press.]]
---

## Comparing ML and REML

```{r echo = F}
music_model_ml <- lmer(na ~ orchestra + large_ensemble + 
                      orchestra:large_ensemble + (large_ensemble|id), 
                      REML = FALSE, data = music)
ml <- tidy(music_model_ml) %>%
  select(term, estimate, std.error) 

reml <- tidy(music_model) %>%
  select(estimate, std.error) 

full <- bind_cols(ml, reml)
```

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-7bx6{border-color:inherit;font-family:Tahoma, Geneva, sans-serif !important;font-size:16px;text-align:left;
  vertical-align:top}
.tg .tg-k70d{border-color:inherit;font-family:Tahoma, Geneva, sans-serif !important;font-size:16px;font-weight:bold;
  text-align:center;vertical-align:top}
.tg .tg-sr1h{border-color:inherit;font-family:Tahoma, Geneva, sans-serif !important;font-size:16px;text-align:right;
  vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-7bx6"></th>
    <th class="tg-k70d" colspan="2">Maximum Likelihood</th>
    <th class="tg-k70d" colspan="2">Restricted Maximum Likelihood</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-k70d">Term</td>
    <td class="tg-k70d">Estimate</td>
    <td class="tg-k70d">Std. Error</td>
    <td class="tg-k70d">Estimate</td>
    <td class="tg-k70d">Std. Error</td>
  </tr>
  <tr>
    <td class="tg-7bx6">(Intercept)</td>
    <td class="tg-sr1h">15.924</td>
    <td class="tg-sr1h">0.623</td>
    <td class="tg-sr1h">15.930</td>
    <td class="tg-sr1h">0.641</td>
  </tr>
  <tr>
    <td class="tg-7bx6">orchestra1</td>
    <td class="tg-sr1h">1.696</td>
    <td class="tg-sr1h">0.919</td>
    <td class="tg-sr1h">1.693</td>
    <td class="tg-sr1h">0.945</td>
  </tr>
  <tr>
    <td class="tg-7bx6">large_ensemble1</td>
    <td class="tg-sr1h">-0.895</td>
    <td class="tg-sr1h">0.827</td>
    <td class="tg-sr1h">-0.911</td>
    <td class="tg-sr1h">0.845</td>
  </tr>
  <tr>
    <td class="tg-7bx6">orchestra1:large_ensemble1</td>
    <td class="tg-sr1h">-1.438</td>
    <td class="tg-sr1h">1.074</td>
    <td class="tg-sr1h">-1.424</td>
    <td class="tg-sr1h">1.099</td>
  </tr>
  <tr>
    <td class="tg-7bx6">sd__(Intercept)</td>
    <td class="tg-sr1h">2.286</td>
    <td class="tg-sr1h">NA</td>
    <td class="tg-sr1h">2.378</td>
    <td class="tg-sr1h">NA</td>
  </tr>
  <tr>
    <td class="tg-7bx6">cor__(Intercept).large_ensemble1</td>
    <td class="tg-sr1h">-1.00</td>
    <td class="tg-sr1h">NA</td>
    <td class="tg-sr1h">-0.635</td>
    <td class="tg-sr1h">NA</td>
  </tr>
  <tr>
    <td class="tg-7bx6">sd__large_ensemble1</td>
    <td class="tg-sr1h">0.385</td>
    <td class="tg-sr1h">NA</td>
    <td class="tg-sr1h">0.672</td>
    <td class="tg-sr1h">NA</td>
  </tr>
  <tr>
    <td class="tg-7bx6">sd__Observation</td>
    <td class="tg-sr1h">4.665</td>
    <td class="tg-sr1h">NA</td>
    <td class="tg-sr1h">4.670</td>
    <td class="tg-sr1h">NA</td>
  </tr>
</tbody>
</table>

---

## Strategy for building multilevel models 

- Conduct exploratory data analysis for Level One and Level Two variables 

- Fit model with no covariates to assess variability at each level 

- Create Level One models. Start with a single term, then add terms as needed. 

- Create Level Two models. Start with a single term, then add terms as needed. Start with equation for intercept term. 

- Begin with the full set of variance components, then remove variance terms as needed. 

*Alternate model building strategy in BMLR Section 8.6*

---

class: middle, center

.question[
Open `lecture-17.Rmd`.
]

See BMLR Sections 8.6 - 8.11 for full step-by-step analysis.
---

## Acknowledgements

The content in the slides is from 
 
- [BMLR: Chapter 8 - Introduction to Multilevel Models](https://bookdown.org/roback/bookdown-BeyondMLR/ch-multilevelintro.html)
  - Sections 8.5 - 8.12
  
 - Singer, J. D. & Willett, J. B. (2003). *Applied longitudinal data analysis: Modeling change and event occurrence*. Oxford university press.    
