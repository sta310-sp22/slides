<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Using likelihoods to compare models</title>
    <meta charset="utf-8" />
    <meta name="author" content="Prof. Maria Tackett" />
    <script src="libs/font-awesome/header-attrs-2.11/header-attrs.js"></script>
    <link href="libs/font-awesome/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="libs/font-awesome/panelset-0.2.6/panelset.js"></script>
    <link rel="stylesheet" href="sta310-slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Using likelihoods to compare models
### Prof. Maria Tackett
### 01.24.22

---












class: middle, center

##[Click for PDF of slides](05-compare-models.pdf)

---

## Announcements

- Project update 

- Week 03 reading: [BMLR: Chapter 3 - Distribution Theory](https://bookdown.org/roback/bookdown-BeyondMLR/ch-distthry.html)

- Quiz 01 due Wed, Jan 26 at 3:30pm (before class)


---

## Learning goals 

- Use likelihood to compare models 

- Review distribution theory 

---

class: middle, inverse

## Recap

---

## Fouls in college basketball games

The data set [`04-refs.csv`](data/04-refs.csv) includes 30 randomly selected NCAA men's basketball games played in the 2009 - 2010 season.

We will focus on the variables `foul1`, `foul2`, and `foul3`, which indicate which team had a foul called them for the 1st, 2nd, and 3rd fouls, respectively. 
  - `H`: Foul was called on the home team 
  - `V`: Foul was called on the visiting team

--

We are focusing on the first three fouls for this analysis, but this could easily be extended to include all fouls in a game. 

.footnote[.small[The dataset was derived from `basektball0910.csv` used in [BMLR Section 11.2](https://bookdown.org/roback/bookdown-BeyondMLR/ch-GLMM.html#cs:refs)]]

---

## Fouls in college basketball games


```r
refs &lt;- read_csv("data/04-refs.csv")
refs %&gt;% slice(1:5) %&gt;% kable()
```



| game|     date|visitor |hometeam |foul1 |foul2 |foul3 |
|----:|--------:|:-------|:--------|:-----|:-----|:-----|
|  166| 20100126|CLEM    |BC       |V     |V     |V     |
|  224| 20100224|DEPAUL  |CIN      |H     |H     |V     |
|  317| 20100109|MARQET  |NOVA     |H     |H     |H     |
|  214| 20100228|MARQET  |SETON    |V     |V     |H     |
|  278| 20100128|SETON   |SFL      |H     |V     |V     |

We will treat the games as independent in this analysis.

---

## Likelihoods 

A **likelihood** is a function that tells us how likely we are to observe our data for a given parameter value (or values). 

--

**Model 1 (Unconditional Model)**

- `\(p_H\)`: probability of a foul being called on the home team

--

**Model 2 (Conditional Model)**

- `\(p_{H|N}\)`: Probability referees call foul on home team given there are equal numbers of fouls on the home and visiting teams
- `\(p_{H|H Bias}\)`: Probability referees call foul on home team given there are more prior fouls on the home team
- `\(p_{H|V Bias}\)`: Probability referees call foul on home team given there are more prior fouls on the visiting team
    

---

## Likelihoods

A **likelihood** is a function that tells us how likely we are to observe our data for a given parameter value (or values). 

**Model 1 (Unconditional Model)**

`$$Lik(p_H) = p_H^{46}(1 - p_H)^{44}$$`

--


**Model 2 (Conditional Model)**

`$$\begin{aligned}Lik(p_{H| N}, p_{H|H Bias}, p_{H |V Bias}) &amp;= [(p_{H| N})^{25}(1 - p_{H|N})^{23}(p_{H| H Bias})^8 \\ &amp;(1 - p_{H| H Bias})^{12}(p_{H| V Bias})^{13}(1-p_{H|V Bias})^9]\end{aligned}$$`     


---

## Maximum likelihood estimates

The **maximum likelihood estimate (MLE)** is the value between 0 and 1 where we are most likely to see the observed data.

--

.pull-left[
**Model 1 (Unconditional Model)**

- `\(\hat{p}_H = 46/90 = 0.511\)`


**Model 2 (Conditional Model)**

- `\(\hat{p}_{H|N} = 25 / 48 = 0.521\)`
- `\(\hat{p}_{H|H Bias} = 8 /20 = 0.4\)`
- `\(\hat{p}_{H|V Bias} = 13/ 22 = 0.591\)`

]

.pull-right[

- What is the probability the referees call a foul on the home team, assuming foul calls within a game are independent? 
- Is there a tendency for the referees to call more fouls on the visiting team or home team? 
- Is there a tendency for referees to call a foul on the team that already has more fouls? 

]

---

class: middle, inverse

## Model comparison 


---

## Model comparisons 

- Nested models 

- Unnested models

---

## Nested Models

**Nested models**: Models such that the parameters of the reduced model are a subset of the parameters for a larger model 

Example: 

`$$\begin{aligned}&amp;\text{Model A: }y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \epsilon\\
&amp;\text{Model B: }y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_4 + \epsilon\end{aligned}$$`

--

Model A is nested in Model B. We could use likelihoods to test whether it is useful to add `\(x_3\)` and `\(x_4\)` to the model. 

`$$\begin{aligned}&amp;H_0: \beta_3 = \beta_4 = 0 \\ 
&amp;H_a: \text{ at least one }\beta_j \text{ is not equal to 0}\end{aligned}$$`

---

## Nested models

**Another way to think about nested models**: Parameters in larger model can be equated to get the simpler model or if some parameters can be set to constants 

Example: 

`$$\begin{aligned}&amp;\text{Model 1: }p_H \\
&amp;\text{Model 2: }p_{H| N}, p_{H| H Bias}, p_{H| V Bias}\end{aligned}$$`

--

Model 1 is nested in Model 2. The parameters `\(p_{H| N}\)`, `\(p_{H|H Bias}\)`, and `\(p_{H |V Bias}\)` can be set to equal `\(p_H\)` to get Model 1. 

`$$\begin{aligned}&amp;H_0: p_{H| N} = p_{H| H Bias} = p_{H| V Bias} = p_H \\
&amp;H_a: \text{At least one of }p_{H| N}, p_{H| H Bias}, p_{H| V Bias} \text{ differs from the others}\end{aligned}$$`

---

## Steps to compare models 

1️⃣  Find the MLEs for each model 

2️⃣  Plug the MLEs into the log-likelihood function for each model to get the maximum value of the log-likelihood for each model. 

3️⃣  Find the difference in the log-likelihoods

4️⃣  Use Likelihood Ratio Test to determine if the difference is statistically significant 

---

## Steps 1 - 2

.pull-left[
**Model 1:**

- `\(\hat{p}_H = 46/90 = 0.511\)`

.small[

```r
loglik1 &lt;- function(ph){
 log(ph^46 * (1 - ph)^44)
}
loglik1(46/90)
```

```
## [1] -62.36102
```
]]


.pull-right[
**Model 2**

- `\(\hat{p}_{H|N} = 25 / 48 = 0.521\)`
- `\(\hat{p}_{H|H Bias} = 8 /20 = 0.4\)`
- `\(\hat{p}_{H|V Bias} = 13/ 22 = 0.591\)`

.small[

```r
loglik2 &lt;- function(phn, phb, phv) {
  log(phn^25 * (1 - phn)^23 * phb^8 * 
        (1 - phb)^12 * phv^13 * (1 - phv)^9)
}
loglik2(25/48, 8/20, 13/22)
```

```
## [1] -61.57319
```
]
]

---

## Step 3

Find the difference in the log-likelihoods


```r
(diff &lt;- loglik2(25/48, 8/20, 13/22) - loglik1(46/90))
```

```
## [1] 0.7878318
```


&lt;br&gt;


--

.center[
**Is the difference in the maximum log-likelihoods statistically significant?** 
]
---

## Likelihood Ratio Test

**Test statistic**

`$$\begin{aligned} LRT &amp;= 2[\max\{\log(Lik(\text{larger model}))\} - \max\{\log(Lik(\text{reduced model}))\}]\\[10pt]
&amp;= 2\log\Bigg(\frac{\max\{(Lik(\text{larger model})\}}{\max\{(Lik(\text{reduced model})\}}\Bigg)\end{aligned}$$`

&lt;br&gt; 

--

LRT follows a `\(\chi^2\)` distribution where the degrees of freedom equal the difference in the number of parameters between the two models

---

## Step 4


```r
(LRT &lt;- 2 * (loglik2(25/48, 8/20, 13/22) - loglik1(46/90)))
```

```
## [1] 1.575664
```

--

The test statistic follows a `\(\chi^2\)` distribution with 2 degrees of freedom. Therefore, the p-value is `\(P(\chi^2 &gt; LRT)\)`. 


```r
pchisq(LRT, 2, lower.tail = FALSE)
```

```
## [1] 0.4548299
```

--

The p-value is very large, so we fail to reject `\(H_0\)`. We do not have convincing evidence that the conditional model is an improvement over the unconditional model. Therefore, we can stick with the unconditional model. 

---

## Comparing non-nested models 

.pull-left[
.midi[**AIC** = -2(max log-likelihood) + 2p]


```r
(Model1_AIC &lt;- 2 * loglik1(46/90) + 2 * 1)
```

```
## [1] -122.722
```

```r
(Model2_AIC &lt;-2 * loglik2(25/48, 8/20, 13/22) + 2 * 3)
```

```
## [1] -117.1464
```
]

--

.pull-right[
.midi[**BIC** = -2(max log-likelihood}) + plog(n)]


```r
(Model1_BIC &lt;- 2 * loglik1(46/90) + 1 * log(30))
```

```
## [1] -121.3208
```

```r
(Model2_BIC &lt;-2 * loglik2(25/48, 8/20, 13/22) + 3 * log(30))
```

```
## [1] -112.9428
```
]

&lt;br&gt;

--


**Choose Model 1 the unconditional model based on AIC and BIC**

---

## Looking ahead

- Likelihoods help us answer the question of how likely we are to observe the data given different parameters

--

- In this example, we did not consider covariates, so in practice our parameters may look more similar to this 

`$$p_H = \frac{e^{\beta_0 + \beta_1x1 + \dots + \beta_px_p}}{1 + e^{\beta_0 + \beta_1x1 + \dots + \beta_px_p}}$$`

--

- Finding the MLE becomes much more complex and numerical methods may be required.
  - We will primarily rely on software to find the MLE, but the conceptual ideas will be the same


---


## Acknowledgements

These slides are based on content in [BMLR Chapter 2 - Beyond Least Squares: Using Likelihoods](https://bookdown.org/roback/bookdown-BeyondMLR/ch-beyondmost.html)

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"slideNumberFormat": "%current%",
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
