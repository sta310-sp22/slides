---
title: "Multilevel models"
date: "02.28.22"
output:
  xaringan::moon_reader:
    #mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    css: "sta310-slides.css"
    logo: sta310-sticker.png
    lib_dir: libs/font-awesome
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "%current%" 
      ratio: "16:9"
    self_contained: true
---

```{r setup, include = F}
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE, 
                      fig.width = 8,
                      fig.asp = 0.618, 
                      fig.retina = 3, 
                      dpt = 300, 
                      out.width = "70%",
                      fig.align = "center")

ggplot2::theme_set(ggplot2::theme_bw(base_size = 16))

colors <- tibble::tibble(green = "#B5BA72")
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(GGally)
library(xaringanExtra)
library(knitr)
library(patchwork)
library(viridis)
library(ggfortify)
library(kableExtra)
```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
```

class: middle, center

## [Click here for PDF of slides](15-multilevel-models.pdf)

---


## Announcements

- HW 03 **due Tue, Mar 01 at 11:59pm**

- Raphaël's office hours this week will be **Tue, 1:30 - 3:30pm**

---

## Learning goals 

- Recognize a potential for correlation in a data set
- Identify observational units at varying levels 
- Understand issues correlated data may cause in modeling
- Understand how random effects models can be used to take correlation into account 
- Use EDA for multilevel data

---

class: middle, inverse

## Correlated observations 

---

## Multilevel data 

- We can think of correlated data as a multilevel structure

  - Population elements are aggregated into groups
  - There are observational units and measurements at each level
  
--

- For now we will focus on data with two levels: 

  - **Level one**: Most basic level of observation 
  - **Level two**: Groups formed from aggregated level-one observations 

---

## Two types of effects

- **Fixed effects**: Effects that are of interest in the study
  - Can think of these as effects whose interpretations would be included in a write up of the study

--

- **Random effects**: Effects we're not interested in studying but whose variability we want to understand 
  - Can think of these as effects whose interpretations would not necessarily be included in a write up of the study  

---

## Practice

.question[
Radon is a carcinogen – a naturally occurring radioactive gas whose decay products are also radioactive – known to cause lung cancer in high concentrations. The EPA sampled more than 80,000 homes across the U.S.  Each house came from a randomly selected county and measurements were made on each level of each home.  Uranium measurements at the county level were included to improve the radon estimates.

1. What is the most basic level of observation (Level One)? 
2. What are the group units (Level Two, Level Three, etc...)
2. What is the response variable?
3. Describe the within-group variation. 
4. What are the fixed effects? What are the random effects?
]

.footnote[Ex. 1 from Section 7.10.1 in BMLR]

```{r echo = F}
library(countdown)
countdown(minutes = 3, seconds = 00,
          margin = "1.25%")
```

---

class: middle, inverse 

## Teratogen and rat pups 

---

## Data: Teratogen and rat pups

Today's data are simulated results of an experiment with 24 dams (mother rats) randomly divided into four groups that received different doses of teratogen, a substance that could potentially cause harm to developing fetuses. The four groups are 

  - High dose (3 mg)
  - Medium dose (2 mg)
  - Low dose (1 mg)
  - No dose (Control)

Each dam produced 10 rat pups and the presence of a deformity was noted. 

--

**Goal**: Understand the association between teratogen exposure and the probability a pup is born with a deformity.

---

## Scenario 1: No dose effect

Assume dose has <u>no</u> effect on, $p$, the probability of a pup born with a deformity.

--

- **Scenario 1a.**: $p = 0.5$ for each dam 

- **Scenario 1b.**: $p \sim Beta(0.5, 0.5)$ (expected value = 0.5)

--

```{r ch7Seed, include = FALSE}
set.seed(2)  # to get the same simulated results as reported here
```

```{r damScenario1, echo = F}
pi_1a <- rep(0.5, 24)
count_1a <- rbinom(24, 10, pi_1a)

pi_1b <- rbeta(24,.5,.5)  
count_1b <- rbinom(24, 10, pi_1b)  
```

```{r scenario1ProbabilityPlot, fig.align="center",out.width="50%", echo=FALSE, warning=FALSE, message=FALSE}
theoretical_pi <- tibble(x = 1:250000,
                         p1 = rbeta(x, 0.5, 0.5))

tibble(x = 1:24, pi_1b) %>%
  ggplot() +
    geom_histogram(bins = 5, aes(x = pi_1b, y = ..density..),
                   color = "black", fill = "blue", alpha = 0.2) + 
    coord_cartesian(xlim = c(0,1)) +
    geom_density(data = theoretical_pi, aes(x = p1), 
                  linetype = 3, color = "blue", lwd = 2) +
    geom_vline(xintercept = 0.5, color = "red", lwd = 2) +
    labs(title = "Probability of deformity", 
         subtitle = "Red = Scenario 1a, Blue dashed line  = Scenario 1b", 
         x = "Probability of Deformity")
```

.footnote[From Figure 7.1 in BMLR]

---

```{r echo = F, out.width = "65%"}
scenario_1 <- 
  tibble(pi_1a, count_1a, pi_1b, count_1b) %>%
  mutate(phat_1a = count_1a / 10, 
         phat_1b = count_1b / 10)

hist_1a <- ggplot(data = scenario_1, aes(x = count_1a)) + 
  geom_histogram(bins = 5, color = "black", fill = "steelblue") +
  coord_cartesian(xlim = c(0, 10)) +
  labs(title = "Scenario 1a: Binomial, p = 0.5",
       x = "Count of deformed pups per dam")

hist_1b <- ggplot(data = scenario_1, aes(x = count_1b)) + 
  geom_histogram(bins = 5, color = "black", fill = "steelblue") +
  coord_cartesian(xlim = c(0, 10)) +
  labs(title = "Scenario 1b: Binomial, p ~ Beta(0.5, 0.5)",
       x = "Count of deformed pups per dam")

hist_1a / hist_1b
```

```{r scenario1Summary, echo = F}
scenario_1 %>% 
  summarise(mean_1a = mean(count_1a), sd_1a = sd(count_1a),
            mean_1b = mean(count_1b), sd_1b = sd(count_1b) ) %>%
  kable()
```

---

class: middle, inverse

## Scenario 2: Dose effect 

---

## Scenario 2: Dose effect

Now we will consider the effect of the dose of teratogen on the probability of a pup born with a deformity. The 24 pups have been randomly divided into four groups: 

  - High dose (`dose = 3`)
  - Medium dose (`dose = 2`)
  - Low dose (`dose = 1`)
  - No dose (`dose = 0`)
  
--

We will assume the true relationship between $p$ and dose is the following: 

$$\log\Big(\frac{p}{1-p}\Big) = -2 + 1.33 ~ dose$$

---

## Scenario 2

**Scenario 2a.**

$$p = \frac{e^{-2 + 1.33 ~ dose}}{1 + e^{-2 + 1.33 ~ dose}}$$

--

**Scenario 2b.** 

$$p \sim Beta\Big(\frac{2p}{(1-p)}, 2\Big)$$

On average, dams who receive dose $x$ have the same probability of deformed pup as dams with dose $x$ under Scenario 2a. 

---

## Distributions under Scenario 2

```{r secnario2aPCalculations, include=FALSE}
x <- 0:3
p_2 <- exp(-2+4/3*x)/(1+exp(-2+4/3*x))
p_2
```

```{r echo = F}
set.seed(1)

dose <- c(rep(0,6),rep(1,6),rep(2,6),rep(3,6))

pi_2a <- exp(-2+4/3*dose)/(1+exp(-2+4/3*dose))
count_2a <- rbinom(24, 10, pi_2a)

b <- 2
a <- b*pi_2a / (1-pi_2a)
pi_2b <- rbeta(24, a, b)
count_2b <- rbinom(24, 10, pi_2b)  
```

```{r, scenario2bPlot, fig.align="center", warning=FALSE, message=FALSE, echo = F}
scenario_2 <- tibble(dose, pi_2a, count_2a, pi_2b, count_2b)
theoretical_pi <- tibble(x = 1:50000,
  p1 = rbeta(x, shape1 = 2*p_2[1]/(1-p_2[1]), shape2 = 2),
  p2 = rbeta(x, shape1 = 2*p_2[2]/(1-p_2[2]), shape2 = 2),
  p3 = rbeta(x, shape1 = 2*p_2[3]/(1-p_2[3]), shape2 = 2),
  p4 = rbeta(x, shape1 = 2*p_2[4]/(1-p_2[4]), shape2 = 2))

hist1 <- ggplot() + 
  geom_histogram(data = scenario_2[1:6,], bins = 5, 
                 aes(x = pi_2b, y = ..density..),
                 color = "black", fill = "blue", alpha = 0.2) + 
  coord_cartesian(xlim = c(0,1)) +
  geom_density(data = theoretical_pi, aes(x = p1), 
               linetype = 3, color = "blue", lwd = 2) +
  geom_vline(xintercept = p_2[1], color = "red", lwd = 2) +
  labs(title = "Dosage = 0 mg", x = "Probability of Deformity")
  

hist2 <- ggplot() + 
  geom_histogram(data = scenario_2[7:12,], 
                 aes(x = pi_2b, y = ..density..), bins = 5,
                 color = "black", fill = "blue", alpha = 0.2) +
  coord_cartesian(xlim = c(0,1)) +
  geom_density(data = theoretical_pi, aes(x = p2), 
               linetype = 3, color = "blue", lwd = 2) +
  geom_vline(xintercept = p_2[2], color = "red", lwd = 2) +
  labs(title = "Dosage = 1 mg", x = "Probability of Deformity")

hist3 <- ggplot() + 
  geom_histogram(data = scenario_2[13:18,], 
                 aes(x = pi_2b, y = ..density..), bins = 5,
                 color = "black", fill = "blue", alpha = 0.2) +
  coord_cartesian(xlim = c(0,1)) +
  geom_density(data = theoretical_pi, aes(x = p3), 
               linetype = 3, color = "blue", lwd = 2) +
  geom_vline(xintercept = p_2[3], color = "red", lwd = 2) +
  labs(title = "Dosage = 2 mg", x = "Probability of Deformity")

hist4 <- ggplot() + 
  geom_histogram(data = scenario_2[19:24,], 
                 aes(x = pi_2b, y = ..density..), bins = 5,
                 color = "black", fill = "blue", alpha = 0.2) +
  coord_cartesian(xlim = c(0,1)) +
  geom_density(data = theoretical_pi, aes(x = p4), 
               linetype = 3, color = "blue", lwd = 2) +
  geom_vline(xintercept = p_2[4], color = "red", lwd = 2) +
  labs(title = "Dosage = 3 mg", x = "Probability of Deformity")

hist1 + hist2 + hist3 + hist4 +  plot_layout(nrow = 2, byrow = FALSE)
```

.footnote[Replicated from Figure 7.3 in BMLR]

---

## Summary statistics under Scenario 2

```{r scenario2Summary, include=FALSE, message=FALSE}
scenario_2 %>% 
  summarise(mean_2a = mean(count_2a), sd_2a = sd(count_2a),
            mean_2b = mean(count_2b), sd_2b = sd(count_2b) )
```

```{r scenario2Tab, echo=FALSE, message=FALSE}
scenario2Tab <- scenario_2 %>%
                  group_by(dose) %>%
                  summarise(mean_2a_pi = round(mean(pi_2a),3), sd_2a_pi = round(sd(pi_2a),3),
                            mean_2a_cnt = round(mean(count_2a),3), sd_2a_cnt = round(sd(count_2a),3),
                            mean_2b_pi = round(mean(pi_2b),3), sd_2b_pi = round(sd(pi_2b),3),
                            mean_2b_cnt = round(mean(count_2b),3), sd_2b_cnt = round(sd(count_2b),3)) %>%
                  as.data.frame()
colnames(scenario2Tab) <- c("Dosage","Mean p", "SD p",
    "Mean Count", "SD Count", "Mean p", "SD p",
    "Mean Count", "SD Count")
kable(scenario2Tab, booktabs = T, 
    caption="Summary statistics of Scenario 2 by dose.") %>%
    add_header_above(c(" " = 1, "Scenario 2a" = 4, 
                       "Scenario 2b" = 4)) %>%
    kable_styling(latex_options = "scale_down") %>%
    column_spec(c(4:5,8:9), width = "1cm")
```

.footnote[From Table 7.2 in BMLR]

---

class: middle 

.question[
1. In Scenario 2a, dams produced 4.79 deformed pups on average, with standard deviation 3.20. Scenario 2b saw an average of 4.67 with standard deviation 3.58. Why are comparisons by dose more meaningful than these overall comparisons? 

2. We will use binomial and quasibinomial regression to model the relationship between dose and probability of pup born with a deformity. What can you say about the center and the width of the confidence intervals under Scenarios 2a and 2b?  
  - Which will be similar and why?  
  - Which will be different and how?
]

---

## Scenario 2: Estimated odds ratio 

.midi[The estimated effect of dose and the 95% CI from the binomial and quasibinomial models are below:] 

**Scenario 2a**

|               | Odds Ratio | 95% CI         |
|---------------|-----------------|----------------|
| Binomial      | 3.536          | (2.604, 4.958) |
| Quasibinomial | 3.536          | (2.512, 5.186) |


**Scenario 2b**

|               | Odds Ratio | 95% CI         |
|---------------|-----------------|----------------|
| Binomial      | 4.311          | (3.086, 6.271) |
| Quasibinomial | 4.311          | (2.735, 7.352) |

---

class: middle 

.question[
1. Describe how the quasibinomial analysis of Scenario 2b differs from the binomial analysis of the same simulated data. Do confidence intervals contain the true model parameters? Is this what you expected? Why? 

2. Why are differences between quasibinomial and binomial models of Scenario 2a less noticeable than the differences in Scenario 2b?
]

---


## Summary 

- The structure of the data set may imply correlation between observations.

- Correlated observations provide less information than independent observations; we need to account for this reduction in information.

- Failing to account for this reduction could result in underestimating standard error, thus resulting in overstating significance and the precision of the estimates.

- We showed how we can account for this by incorporating the dispersion parameter or a random effect.


---

class: middle, inverse

## Multilevel models

---

## Data: Music performance anxiety 

.midi[The data [`musicdata.csv`](data/musicdata.csv) come from the Sadler and Miller (2010) study of the emotional state of musicians before performances. The dataset contains information collected from 37 undergraduate music majors who completed the Positive Affect Negative Affect Schedule (PANAS), an instrument produces a measure of anxiety (negative affect) and a measure of happiness (positive affect). This analysis will focus on negative affect as a measure of performance anxiety.]

The primary variables we'll use are

- **`na`**: negative affect score on PANAS (the response variable)
- **`perform_type`**: type of performance (Solo, Large Ensemble, Small Ensemble)
- **`instrument`**: type of intstrument (Voice, Orchestral, Piano)

---

## Look at data

.small[
```{r echo = F}
music <- read_csv("data/musicdata.csv")
music %>%
  filter(id %in% c(1, 43)) %>%
  group_by(id) %>%
  slice(1:3) %>%
  select(id, diary, perform_type, na, gender, instrument) %>%
  kable()
```
]

- What are the Level One observations? Level Two observations? 


- What are the Level One variables? Level Two variables?

---

## Univariate exploratory data analysis 

**Level One variables** 

Two ways to approach univariate EDA (visualizations and summary statistics) for Level One variables: 

- Use individual observations (i.e., treat observations as independent)

- Use aggregated values for each Level Two observation 

--

**Level Two variables** 

- Use a data set that contains one row per Level Two observation 

.question[
Complete Part 1: Univariate EDA in `lecture-15.Rmd`
]

```{r echo = F}
library(countdown)
countdown(minutes = 8, seconds = 00,
          margin = "1.25%")
```

---

## Bivariate exploratory data analysis

**Goals**

- Explore general association between the predictor and response variable 
- Explore whether subjects at a given level of the predictor tend to have similar mean responses 
- Explore whether variation in response differs at different levels of a predictor


There are two ways to visualize these associations: 

- One plot of individual observations (i.e., treat observations as independent)

- Separate plots of responses vs. predictor for each Level Two observation (lattice plots)

.question[
Complete Part 2: Bivariate EDA in `lecture-15.Rmd`
]

```{r echo = F}
library(countdown)
countdown(minutes = 6, seconds = 00,
          margin = "1.25%")
```


---

class: middle, inverse

## Fitting the model 

---

## Questions we want to answer 

The goal is to understand variability in performance anxiety (`na`) based on performance-level and musician-level characteristics. Specifically: 

- What is the association between performance type (large ensemble or not) and performance anxiety? Does the association differ based on instrument type (orchestral or not)?  

--

.midi[**What is the problem with using the following model to draw conclusions?**]

```{r echo = F}
music <- music %>%
  mutate(orchestra = if_else(instrument == "orchestral instrument", 1, 0), 
         large_ensemble = if_else(perform_type == "Large Ensemble", 1,0))

ols <- lm(na ~ orchestra + large_ensemble + orchestra * large_ensemble, 
          data = music)
tidy(ols) %>% kable(digits = 3)
```

---

## Other modeling approaches 

`r emo::ji("one")`  Condense each musician's set of responses into a single outcome (e.g., mean max, last observation, etc.) and fit a linear model on these condensed observations 

- Leaves few observations (37) to fit the model
- Ignoring a lot of information in the multiple observations for each musician

--

`r emo::ji("two")` Fit a separate model for each musician understand the association between performance type (Level One models). Then fit a system of Level Two models to predict the fitted coefficients in the Level One model for each subject based on instrument type (Level Two model).

--

**Let's look at approach #2**

---

## Two-level model 

We'll start with the Level One model to understand the association between performance type and performance anxiety for the $i^{th}$ musician. 

.eq[
$$na_{ij} = a_i + b_i ~ LargeEnsemble_{ij} + \epsilon_i, \hspace{5mm} \epsilon_{ij} \sim N(0,\sigma^2)$$
]


Why is it more meaningful to use performance type for the Level One model than instrument? 

--

For now, estimate $a_i$ and $b_i$ using least-squares regression.

---

## Example Level One model    

Below is partial data for observation #22

```{r echo = F}
music %>%
  filter(id == 22) %>%
  select(id, diary, perform_type, instrument, na) %>%
  slice(1:3, 13:15) %>%
  kable()
```

---

## Level One model

```{r}
music %>%
  filter(id == 22) %>%
  lm(na ~ large_ensemble, data = .) %>%
  tidy() %>%
  kable(digits = 3)
```

--

**Repeat for all 37 musicians. See Part 3: Level One Models in `lecture-15.Rmd`.**

---

```{r echo = F}
# set up tibble for fitted values 

model_stats <- tibble(slopes = rep(0,37), 
               intercepts = rep(0,37), 
               r.squared = rep(0, 37))


ids <- music %>% distinct(id) %>% pull()

# counter to keep track of row number to store model_stats

count <- 1

for(i in ids){
level_one_model <- music %>%
  filter(id == i) %>%
  lm(na ~ large_ensemble, data = .)

level_one_model_tidy <- tidy(level_one_model)


model_stats$slopes[count] <- level_one_model_tidy$estimate[2]
model_stats$intercepts[count] <- level_one_model_tidy$estimate[1]
model_stats$r.squared[count] <- glance(level_one_model)$r.squared

count = count + 1
}
```

```{r echo = F, fig.cap = "Recreated from BMLR Figure 8.9"}
p1 <- ggplot(data = model_stats, aes(x = intercepts)) + 
  geom_histogram(fill = "steelblue", color = "black", binwidth = 2) + 
  labs(x = "Fitted intercepts", 
      title  = "Intercepts", 
      subtitle = "from 37 musicians")

p2 <- ggplot(data = model_stats, aes(x = slopes)) + 
  geom_histogram(fill = "steelblue", color = "black", binwidth = 2) + 
  labs(x = "Fitted Slopes", 
      title  = "Slopes", 
      subtitle = "from 37 musicians")

p1 + p2
```

--

**Now let's consider if there is an association between the estimated slopes, estimated intercepts, and the type of instrument**

---

## Level Two Model 

The slope and intercept for the $i^{th}$ musician can be modeled as

.eq[
$$\begin{aligned}&a_i = \alpha_0 + \alpha_1 ~ Orchestra_i + u_i \\
&b_i = \beta_0 + \beta_1 ~ Orchestra_i + v_i\end{aligned}$$
]


Note the response variable in the Level Two models are not observed outcomes but the (fitted) slope and intercept from each musician

**See Part 4: Level Two Models in `lecture-15.Rmd`.**

---

## Estimated coefficients by instrument 

```{r echo = F}

musicians <- music %>%
  distinct(id, orchestra) %>%
  bind_cols(model_stats)

p1 <- ggplot(data = musicians, aes(x = intercepts, y = factor(orchestra))) + 
  geom_boxplot(fill = "steelblue", color = "black") + 
  labs(x = "Fitted intercepts", 
       y = "Orchestra")

p2 <- ggplot(data = musicians, aes(x = slopes, y = factor(orchestra))) + 
  geom_boxplot(fill = "steelblue", color = "black") + 
  labs(x = "Fitted slopes", 
       y = "Orchestra")

p1 / p2
```

---

## Level Two model 

**Model for intercepts**

```{r echo = F}
a <- lm(intercepts ~ orchestra, data = musicians) 
tidy(a) %>%
  kable(digits = 3)
```

**Model for slopes**

```{r echo = F}
b <- lm(slopes ~ orchestra, data = musicians) 
tidy(b) %>%
  kable(digits = 3)
```

---

## Writing out the models 

**Level One** 

$$\hat{na}_{ij}  = \hat{a}_i + \hat{b}_i ~ LargeEnsemble_{ij}$$

for each musician. 

**Level Two** 

$$\begin{aligned}&\hat{a}_i = 16.283 + 1.441 ~ Orchestra_i \\
&\hat{b}_i = -0.771 - 1.406 ~ Orchestra_i\end{aligned}$$

---

## Composite model 

.eq[
$$\begin{aligned}\hat{na}_i &= 16.283 + 1.441 ~ Orchestra_i - 0.771 ~ LargeEnsemble_{ij} \\
&- 1.406 ~ Orchestra:LargeEnsemble_{ij}\end{aligned}$$
]

(Note that we also have the error terms $\epsilon_{ij}, u_i, v_i$ that we will discuss next class.)

- What is the predicted average performance anxiety before solos and small ensemble performances for vocalists and keyboardists? For those who place orchestral instruments? 

- What is the predicted average performance anxiety before large ensemble performances for those who play orchestral instruments?


---

## Disadvantages to this approach 

`r emo::ji("warning")` Weighs each musician the same regardless of number of diary entries

`r emo::ji("warning")`  Drops subjects who have missing values for slope (7 individuals who didn't play a large ensemble performance) 

`r emo::ji("warning")`  Does not share strength effectively across individuals 

.question[
Plot the $R^2$ values calculated in Part 3: Level One Model of `lecture-15.Rmd`.
]

--

**We will use a unified approach that utilizes likelihood-based methods to address some of these drawbacks.**


---

## Acknowledgements

The content in the slides is from 
  - [BMLR: Chapter 7 - Correlated data](https://bookdown.org/roback/bookdown-BeyondMLR/ch-corrdata.html)
  - [BMLR: Chapter 8 - Introduction to Multilevel Models](https://bookdown.org/roback/bookdown-BeyondMLR/ch-multilevelintro.html)

- Sadler, Michael E., and Christopher J. Miller. 2010. “Performance Anxiety: A Longitudinal Study of the Roles of Personality and Experience in Musicians.” Social Psychological and Personality Science 1 (3): 280–87. http://dx.doi.org/10.1177/1948550610370492.
  